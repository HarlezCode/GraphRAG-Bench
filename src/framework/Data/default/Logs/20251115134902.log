2025-11-15 13:49:19.364 | INFO     | Core.Utils.ComponentRegistry:register_component:273 - âœ… Registered component: graph_builder (general)
2025-11-15 13:49:19.365 | INFO     | Core.Utils.ComponentRegistry:register_component:273 - âœ… Registered component: document_processor (general)
2025-11-15 13:49:24.259 | WARNING  | Core.Indexing.IndexManagerFactory:create_manager:437 - Failed to create embedding model: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 26.62 MiB is free. Process 2248509 has 21.78 GiB memory in use. Including non-PyTorch memory, this process has 1.79 GiB memory in use. Of the allocated memory 1.41 GiB is allocated by PyTorch, and 4.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-11-15 13:49:24.419 | INFO     | Core.Utils.ComponentRegistry:register_component:273 - âœ… Registered component: index_manager (general)
2025-11-15 13:49:24.435 | INFO     | Core.Utils.ComponentRegistry:register_component:273 - âœ… Registered component: query_processor (general)
2025-11-15 13:49:24.436 | INFO     | Core.Utils.ComponentRegistry:register_component:273 - âœ… Registered component: storage_manager (general)
2025-11-15 13:49:24.564 | INFO     | Core.Engine.GraphRAGEngine:process_documents:188 - ğŸš€ Starting document processing workflow
2025-11-15 13:49:25.865 | WARNING  | tenacity.after:log_it:44 - Finished call to 'Core.Provider.OpenaiApi.OpenAILLM.acompletion_text' after 1.205(s), this was the 1st time calling it.
2025-11-15 13:49:28.154 | WARNING  | tenacity.after:log_it:44 - Finished call to 'Core.Provider.OpenaiApi.OpenAILLM.acompletion_text' after 3.495(s), this was the 2nd time calling it.
2025-11-15 13:49:31.242 | WARNING  | tenacity.after:log_it:44 - Finished call to 'Core.Provider.OpenaiApi.OpenAILLM.acompletion_text' after 6.583(s), this was the 3rd time calling it.
2025-11-15 13:49:35.478 | WARNING  | tenacity.after:log_it:44 - Finished call to 'Core.Provider.OpenaiApi.OpenAILLM.acompletion_text' after 10.818(s), this was the 4th time calling it.
2025-11-15 13:49:44.212 | WARNING  | tenacity.after:log_it:44 - Finished call to 'Core.Provider.OpenaiApi.OpenAILLM.acompletion_text' after 19.553(s), this was the 5th time calling it.
2025-11-15 13:50:00.141 | WARNING  | tenacity.after:log_it:44 - Finished call to 'Core.Provider.OpenaiApi.OpenAILLM.acompletion_text' after 35.482(s), this was the 6th time calling it.
2025-11-15 13:50:00.141 | ERROR    | Core.Common.Utils:log_and_reraise:312 - Retry attempts exhausted. Last exception: Connection error.
2025-11-15 13:50:00.141 | WARNING  | Core.Common.Utils:log_and_reraise:313 - 
Recommend going to https://deepwisdom.feishu.cn/wiki/MsGnwQBjiif9c3koSJNcYaoSnu4#part-XdatdVlhEojeAfxaaEZcMV3ZniQ
See FAQ 5.8

2025-11-15 13:50:00.142 | ERROR    | Core.Engine.GraphRAGEngine:process_documents:238 - âŒ Document processing failed: Connection error.
2025-11-15 13:50:00.142 | ERROR    | __main__:main:243 - Application execution failed
Traceback (most recent call last):

  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/httpx/_transports/default.py", line 394, in handle_async_request
    resp = await self._pool.handle_async_request(req)
                 â”‚    â”‚     â”‚                    â”” <Request [b'POST']>
                 â”‚    â”‚     â”” <function AsyncConnectionPool.handle_async_request at 0x777016d27e20>
                 â”‚    â”” <AsyncConnectionPool [Requests: 0 active, 0 queued | Connections: 0 active, 0 idle]>
                 â”” <httpx.AsyncHTTPTransport object at 0x77701732ef50>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 256, in handle_async_request
    raise exc from None
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/httpcore/_async/connection_pool.py", line 236, in handle_async_request
    response = await connection.handle_async_request(
                     â”‚          â”” <function AsyncHTTPConnection.handle_async_request at 0x777016d271a0>
                     â”” <AsyncHTTPConnection [CONNECTION FAILED]>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/httpcore/_async/connection.py", line 101, in handle_async_request
    raise exc
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/httpcore/_async/connection.py", line 78, in handle_async_request
    stream = await self._connect(request)
                   â”‚    â”‚        â”” <Request [b'POST']>
                   â”‚    â”” <function AsyncHTTPConnection._connect at 0x777016d27240>
                   â”” <AsyncHTTPConnection [CONNECTION FAILED]>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/httpcore/_async/connection.py", line 124, in _connect
    stream = await self._network_backend.connect_tcp(**kwargs)
                   â”‚    â”‚                â”‚             â”” {'host': '0.0.0.0', 'port': 8000, 'local_address': None, 'timeout': 600, 'socket_options': None}
                   â”‚    â”‚                â”” <function AutoBackend.connect_tcp at 0x777016d25080>
                   â”‚    â”” <httpcore._backends.auto.AutoBackend object at 0x777017005b50>
                   â”” <AsyncHTTPConnection [CONNECTION FAILED]>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/httpcore/_backends/auto.py", line 31, in connect_tcp
    return await self._backend.connect_tcp(
                 â”‚    â”‚        â”” <function AnyIOBackend.connect_tcp at 0x777016d3ede0>
                 â”‚    â”” <httpcore.AnyIOBackend object at 0x776fe87c5890>
                 â”” <httpcore._backends.auto.AutoBackend object at 0x777017005b50>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/httpcore/_backends/anyio.py", line 113, in connect_tcp
    with map_exceptions(exc_map):
         â”‚              â”” {<class 'TimeoutError'>: <class 'httpcore.ConnectTimeout'>, <class 'OSError'>: <class 'httpcore.ConnectError'>, <class 'anyio...
         â”” <function map_exceptions at 0x777016ca5940>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
    â”‚    â”‚   â”‚     â”‚    â”‚      â”” <traceback object at 0x776fe877d080>
    â”‚    â”‚   â”‚     â”‚    â”” OSError('All connection attempts failed')
    â”‚    â”‚   â”‚     â”” <class 'OSError'>
    â”‚    â”‚   â”” <method 'throw' of 'generator' objects>
    â”‚    â”” <generator object map_exceptions at 0x776fe8d0c540>
    â”” <contextlib._GeneratorContextManager object at 0x776fe877fcd0>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
          â”” <class 'httpcore.ConnectError'>

httpcore.ConnectError: All connection attempts failed


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/openai/_base_client.py", line 1500, in _request
    response = await self._client.send(
                     â”‚    â”‚       â”” <function AsyncClient.send at 0x777018827b00>
                     â”‚    â”” <openai._base_client.AsyncHttpxClientWrapper object at 0x777016e574d0>
                     â”” <openai.AsyncOpenAI object at 0x777017006d50>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
                     â”‚    â”” <function AsyncClient._send_handling_auth at 0x777018827ba0>
                     â”” <openai._base_client.AsyncHttpxClientWrapper object at 0x777016e574d0>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
                     â”‚    â”” <function AsyncClient._send_handling_redirects at 0x777018827c40>
                     â”” <openai._base_client.AsyncHttpxClientWrapper object at 0x777016e574d0>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
                     â”‚    â”‚                    â”” <Request('POST', 'http://0.0.0.0:8000/v1/chat/completions')>
                     â”‚    â”” <function AsyncClient._send_single_request at 0x777018827ce0>
                     â”” <openai._base_client.AsyncHttpxClientWrapper object at 0x777016e574d0>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
                     â”‚         â”‚                    â”” <Request('POST', 'http://0.0.0.0:8000/v1/chat/completions')>
                     â”‚         â”” <function AsyncHTTPTransport.handle_async_request at 0x7770188247c0>
                     â”” <httpx.AsyncHTTPTransport object at 0x77701732ef50>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/httpx/_transports/default.py", line 393, in handle_async_request
    with map_httpcore_exceptions():
         â”” <function map_httpcore_exceptions at 0x77701880fd80>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
    â”‚    â”‚   â”‚     â”‚    â”‚      â”” <traceback object at 0x776fe877ce80>
    â”‚    â”‚   â”‚     â”‚    â”” ConnectError(OSError('All connection attempts failed'))
    â”‚    â”‚   â”‚     â”” <class 'httpcore.ConnectError'>
    â”‚    â”‚   â”” <method 'throw' of 'generator' objects>
    â”‚    â”” <generator object map_httpcore_exceptions at 0x776fe8d0c240>
    â”” <contextlib._GeneratorContextManager object at 0x776fe878da50>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
          â”‚          â”” 'All connection attempts failed'
          â”” <class 'httpx.ConnectError'>

httpx.ConnectError: All connection attempts failed


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/main.py", line 252, in <module>
    asyncio.run(main())
    â”‚       â”‚   â”” <function main at 0x777019169260>
    â”‚       â”” <function run at 0x77719d365ee0>
    â”” <module 'asyncio' from '/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/__init__.py'>

  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           â”‚      â”‚   â”” <coroutine object main at 0x7770193bfde0>
           â”‚      â”” <function Runner.run at 0x77719cd51620>
           â”” <asyncio.runners.Runner object at 0x777148311190>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           â”‚    â”‚     â”‚                  â”” <Task pending name='Task-1' coro=<main() running at /data2/chhuangab/projects/GraphRAG-Bench/src/framework/main.py:243> cb=[_...
           â”‚    â”‚     â”” <function BaseEventLoop.run_until_complete at 0x77719cd4f1a0>
           â”‚    â”” <_UnixSelectorEventLoop running=True closed=False debug=False>
           â”” <asyncio.runners.Runner object at 0x777148311190>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/base_events.py", line 641, in run_until_complete
    self.run_forever()
    â”‚    â”” <function BaseEventLoop.run_forever at 0x77719cd4f100>
    â”” <_UnixSelectorEventLoop running=True closed=False debug=False>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/base_events.py", line 608, in run_forever
    self._run_once()
    â”‚    â”” <function BaseEventLoop._run_once at 0x77719cd50f40>
    â”” <_UnixSelectorEventLoop running=True closed=False debug=False>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/base_events.py", line 1936, in _run_once
    handle._run()
    â”‚      â”” <function Handle._run at 0x77719d366980>
    â”” <Handle Task.task_wakeup(<Future finished result=None>)>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
    â”‚    â”‚            â”‚    â”‚           â”‚    â”” <member '_args' of 'Handle' objects>
    â”‚    â”‚            â”‚    â”‚           â”” <Handle Task.task_wakeup(<Future finished result=None>)>
    â”‚    â”‚            â”‚    â”” <member '_callback' of 'Handle' objects>
    â”‚    â”‚            â”” <Handle Task.task_wakeup(<Future finished result=None>)>
    â”‚    â”” <member '_context' of 'Handle' objects>
    â”” <Handle Task.task_wakeup(<Future finished result=None>)>

> File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/main.py", line 223, in main
    await app.process_documents(force_rebuild=args.force_rebuild)
          â”‚   â”‚                               â”‚    â”” False
          â”‚   â”‚                               â”” Namespace(opt='Option/merged_config.yaml', dataset_name='GraphRAG-Bench', method='hippo_rag', force_rebuild=False, max_querie...
          â”‚   â”” <function GraphRAGApplication.process_documents at 0x777019147920>
          â”” <__main__.GraphRAGApplication object at 0x777022d2cc50>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/main.py", line 63, in process_documents
    await self.engine.process_documents(corpus, force_rebuild=force_rebuild)
          â”‚    â”‚      â”‚                 â”‚                     â”” False
          â”‚    â”‚      â”‚                 â”” [{'title': 'What is an algorithm? N/A N/A', 'content': '\n\nIntroduction \n0.1 What is an algorithm? \nAn algorithm is an exp...
          â”‚    â”‚      â”” <function GraphRAGEngine.process_documents at 0x777141bd0900>
          â”‚    â”” GraphRAGEngine(config=MergedConfig(extra_fields=None, working_dir='./Data/GraphRAG-Bench', exp_name='default', data_root='./D...
          â”” <__main__.GraphRAGApplication object at 0x777022d2cc50>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Engine/GraphRAGEngine.py", line 198, in process_documents
    await self._execute_stage("graph_construction", chunks, force_rebuild)
          â”‚    â”‚                                    â”‚       â”” False
          â”‚    â”‚                                    â”” [TextChunk(tokens=1200, chunk_id='0', content="{'title': 'What is an algorithm? N/A N/A', 'content': '\\n\\nIntroduction \\n0...
          â”‚    â”” <function GraphRAGEngine._execute_stage at 0x777141bd09a0>
          â”” GraphRAGEngine(config=MergedConfig(extra_fields=None, working_dir='./Data/GraphRAG-Bench', exp_name='default', data_root='./D...

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Engine/GraphRAGEngine.py", line 246, in _execute_stage
    await stage.execute(*args, **kwargs)
          â”‚     â”‚        â”‚       â”” {}
          â”‚     â”‚        â”” ([TextChunk(tokens=1200, chunk_id='0', content="{'title': 'What is an algorithm? N/A N/A', 'content': '\\n\\nIntroduction \\n...
          â”‚     â”” <function EntityRelationGraphBuilder.execute at 0x776fe86e74c0>
          â”” <Core.Graph.GraphBuilderFactory.EntityRelationGraphBuilder object at 0x776fe8640210>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Graph/GraphBuilderFactory.py", line 95, in execute
    self.graph = await self._build_graph(chunks)
    â”‚    â”‚             â”‚    â”‚            â”” [TextChunk(tokens=1200, chunk_id='0', content="{'title': 'What is an algorithm? N/A N/A', 'content': '\\n\\nIntroduction \\n0...
    â”‚    â”‚             â”‚    â”” <function EntityRelationGraphBuilder._build_graph at 0x776fe86e7560>
    â”‚    â”‚             â”” <Core.Graph.GraphBuilderFactory.EntityRelationGraphBuilder object at 0x776fe8640210>
    â”‚    â”” None
    â”” <Core.Graph.GraphBuilderFactory.EntityRelationGraphBuilder object at 0x776fe8640210>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Graph/GraphBuilderFactory.py", line 107, in _build_graph
    entities, relationships = await self._extract_entities_relations(chunk)
                                    â”‚    â”‚                           â”” TextChunk(tokens=1200, chunk_id='0', content="{'title': 'What is an algorithm? N/A N/A', 'content': '\\n\\nIntroduction \\n0....
                                    â”‚    â”” <function EntityRelationGraphBuilder._extract_entities_relations at 0x776fe86e7600>
                                    â”” <Core.Graph.GraphBuilderFactory.EntityRelationGraphBuilder object at 0x776fe8640210>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Graph/GraphBuilderFactory.py", line 135, in _extract_entities_relations
    entities = await self._named_entity_recognition(chunk.content)
                     â”‚    â”‚                         â”‚     â”” "{'title': 'What is an algorithm? N/A N/A', 'content': '\\n\\nIntroduction \\n0.1 What is an algorithm? \\nAn algorithm is an...
                     â”‚    â”‚                         â”” TextChunk(tokens=1200, chunk_id='0', content="{'title': 'What is an algorithm? N/A N/A', 'content': '\\n\\nIntroduction \\n0....
                     â”‚    â”” <function EntityRelationGraphBuilder._named_entity_recognition at 0x776fe86e76a0>
                     â”” <Core.Graph.GraphBuilderFactory.EntityRelationGraphBuilder object at 0x776fe8640210>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Graph/GraphBuilderFactory.py", line 171, in _named_entity_recognition
    response = await self.llm.aask(ner_messages, format="json")
                     â”‚    â”‚   â”‚    â”” 'Your task is to extract named entities from the given paragraph. \nRespond with a JSON list of entities.\n\nPlease reference...
                     â”‚    â”‚   â”” <function BaseLLM.aask at 0x777016e4e3e0>
                     â”‚    â”” <Core.Provider.OpenaiApi.OpenAILLM object at 0x777016fbbed0>
                     â”” <Core.Graph.GraphBuilderFactory.EntityRelationGraphBuilder object at 0x776fe8640210>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Provider/BaseLLM.py", line 146, in aask
    rsp = await self.acompletion_text(message, stream=stream, timeout=self.get_timeout(timeout), max_tokens = max_tokens, format = format)
                â”‚    â”‚                â”‚               â”‚               â”‚    â”‚           â”‚                      â”‚                    â”” 'json'
                â”‚    â”‚                â”‚               â”‚               â”‚    â”‚           â”‚                      â”” None
                â”‚    â”‚                â”‚               â”‚               â”‚    â”‚           â”” 0
                â”‚    â”‚                â”‚               â”‚               â”‚    â”” <function BaseLLM.get_timeout at 0x777016e4f100>
                â”‚    â”‚                â”‚               â”‚               â”” <Core.Provider.OpenaiApi.OpenAILLM object at 0x777016fbbed0>
                â”‚    â”‚                â”‚               â”” False
                â”‚    â”‚                â”” [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Your task is to extract named en...
                â”‚    â”” <function OpenAILLM.acompletion_text at 0x777016e4fe20>
                â”” <Core.Provider.OpenaiApi.OpenAILLM object at 0x777016fbbed0>

  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/tenacity/asyncio/__init__.py", line 189, in async_wrapped
    return await copy(fn, *args, **kwargs)
                 â”‚    â”‚    â”‚       â”” {'stream': False, 'timeout': 600, 'max_tokens': None, 'format': 'json'}
                 â”‚    â”‚    â”” (<Core.Provider.OpenaiApi.OpenAILLM object at 0x777016fbbed0>, [{'role': 'system', 'content': 'You are a helpful assistant.'}...
                 â”‚    â”” <function OpenAILLM.acompletion_text at 0x777016e4fba0>
                 â”” <AsyncRetrying object at 0x776fe87e4d10 (stop=<tenacity.stop.stop_after_attempt object at 0x77701725d750>, wait=<tenacity.wai...
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/tenacity/asyncio/__init__.py", line 111, in __call__
    do = await self.iter(retry_state=retry_state)
               â”‚    â”‚                â”” <RetryCallState 131317954049616: attempt #6; slept for 27.46; last result: failed (APIConnectionError Connection error.)>
               â”‚    â”” <function AsyncRetrying.iter at 0x77701727fe20>
               â”” <AsyncRetrying object at 0x776fe87e4d10 (stop=<tenacity.stop.stop_after_attempt object at 0x77701725d750>, wait=<tenacity.wai...
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
                   â”‚      â”” <RetryCallState 131317954049616: attempt #6; slept for 27.46; last result: failed (APIConnectionError Connection error.)>
                   â”” <function wrap_to_async_func.<locals>.inner at 0x776fe8902480>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
           â”‚     â”‚       â”” {}
           â”‚     â”” (<RetryCallState 131317954049616: attempt #6; slept for 27.46; last result: failed (APIConnectionError Connection error.)>,)
           â”” <function log_and_reraise at 0x7770171113a0>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Common/Utils.py", line 319, in log_and_reraise
    raise retry_state.outcome.exception()
          â”‚           â”‚       â”” <function Future.exception at 0x77719d504cc0>
          â”‚           â”” <Future at 0x776fe877dad0 state=finished raised APIConnectionError>
          â”” <RetryCallState 131317954049616: attempt #6; slept for 27.46; last result: failed (APIConnectionError Connection error.)>

  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/tenacity/asyncio/__init__.py", line 114, in __call__
    result = await fn(*args, **kwargs)
                   â”‚   â”‚       â”” {'stream': False, 'timeout': 600, 'max_tokens': None, 'format': 'json'}
                   â”‚   â”” (<Core.Provider.OpenaiApi.OpenAILLM object at 0x777016fbbed0>, [{'role': 'system', 'content': 'You are a helpful assistant.'}...
                   â”” <function OpenAILLM.acompletion_text at 0x777016e4fba0>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Provider/OpenaiApi.py", line 157, in acompletion_text
    rsp = await self._achat_completion(messages, timeout=self.get_timeout(timeout), max_tokens = max_tokens)
                â”‚    â”‚                 â”‚                 â”‚    â”‚           â”‚                      â”” None
                â”‚    â”‚                 â”‚                 â”‚    â”‚           â”” 600
                â”‚    â”‚                 â”‚                 â”‚    â”” <function BaseLLM.get_timeout at 0x777016e4f100>
                â”‚    â”‚                 â”‚                 â”” <Core.Provider.OpenaiApi.OpenAILLM object at 0x777016fbbed0>
                â”‚    â”‚                 â”” [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Your task is to extract named en...
                â”‚    â”” <function OpenAILLM._achat_completion at 0x777016e4f880>
                â”” <Core.Provider.OpenaiApi.OpenAILLM object at 0x777016fbbed0>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Provider/OpenaiApi.py", line 138, in _achat_completion
    rsp: ChatCompletion = await self.aclient.chat.completions.create(**kwargs)
                                â”‚    â”‚       â”‚    â”‚           â”‚        â”” {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Your task is to ext...
                                â”‚    â”‚       â”‚    â”‚           â”” <function AsyncCompletions.create at 0x7770173fe200>
                                â”‚    â”‚       â”‚    â”” <openai.resources.chat.completions.completions.AsyncCompletions object at 0x776ed807cc50>
                                â”‚    â”‚       â”” <openai.resources.chat.chat.AsyncChat object at 0x777017158850>
                                â”‚    â”” <openai.AsyncOpenAI object at 0x777017006d50>
                                â”” <Core.Provider.OpenaiApi.OpenAILLM object at 0x777016fbbed0>

  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2002, in create
    return await self._post(
                 â”‚    â”” <bound method AsyncAPIClient.post of <openai.AsyncOpenAI object at 0x777017006d50>>
                 â”” <openai.resources.chat.completions.completions.AsyncCompletions object at 0x776ed807cc50>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/openai/_base_client.py", line 1767, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
                 â”‚    â”‚       â”‚        â”‚            â”‚                  â”” openai.AsyncStream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
                 â”‚    â”‚       â”‚        â”‚            â”” False
                 â”‚    â”‚       â”‚        â”” FinalRequestOptions(method='post', url='/chat/completions', params={}, headers=NOT_GIVEN, max_retries=NOT_GIVEN, timeout=600,...
                 â”‚    â”‚       â”” <class 'openai.types.chat.chat_completion.ChatCompletion'>
                 â”‚    â”” <function AsyncAPIClient.request at 0x7770178479c0>
                 â”” <openai.AsyncOpenAI object at 0x777017006d50>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/openai/_base_client.py", line 1461, in request
    return await self._request(
                 â”‚    â”” <function AsyncAPIClient._request at 0x777017847a60>
                 â”” <openai.AsyncOpenAI object at 0x777017006d50>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/openai/_base_client.py", line 1524, in _request
    return await self._retry_request(
                 â”‚    â”” <function AsyncAPIClient._retry_request at 0x777017847b00>
                 â”” <openai.AsyncOpenAI object at 0x777017006d50>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in _retry_request
    return await self._request(
                 â”‚    â”” <function AsyncAPIClient._request at 0x777017847a60>
                 â”” <openai.AsyncOpenAI object at 0x777017006d50>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/openai/_base_client.py", line 1524, in _request
    return await self._retry_request(
                 â”‚    â”” <function AsyncAPIClient._retry_request at 0x777017847b00>
                 â”” <openai.AsyncOpenAI object at 0x777017006d50>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in _retry_request
    return await self._request(
                 â”‚    â”” <function AsyncAPIClient._request at 0x777017847a60>
                 â”” <openai.AsyncOpenAI object at 0x777017006d50>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/openai/_base_client.py", line 1534, in _request
    raise APIConnectionError(request=request) from err
          â”‚                          â”” <Request('POST', 'http://0.0.0.0:8000/v1/chat/completions')>
          â”” <class 'openai.APIConnectionError'>

openai.APIConnectionError: Connection error.
