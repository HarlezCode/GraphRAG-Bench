2025-11-15 13:50:46.275 | INFO     | Core.Utils.ComponentRegistry:register_component:273 - âœ… Registered component: graph_builder (general)
2025-11-15 13:50:46.276 | INFO     | Core.Utils.ComponentRegistry:register_component:273 - âœ… Registered component: document_processor (general)
2025-11-15 13:50:50.138 | WARNING  | Core.Indexing.IndexManagerFactory:create_manager:437 - Failed to create embedding model: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 26.62 MiB is free. Process 2248509 has 21.78 GiB memory in use. Including non-PyTorch memory, this process has 1.79 GiB memory in use. Of the allocated memory 1.41 GiB is allocated by PyTorch, and 4.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-11-15 13:50:50.298 | INFO     | Core.Utils.ComponentRegistry:register_component:273 - âœ… Registered component: index_manager (general)
2025-11-15 13:50:50.301 | INFO     | Core.Utils.ComponentRegistry:register_component:273 - âœ… Registered component: query_processor (general)
2025-11-15 13:50:50.301 | INFO     | Core.Utils.ComponentRegistry:register_component:273 - âœ… Registered component: storage_manager (general)
2025-11-15 13:50:50.317 | INFO     | Core.Engine.GraphRAGEngine:process_documents:188 - ğŸš€ Starting document processing workflow
2025-11-15 13:50:50.419 | WARNING  | tenacity.after:log_it:44 - Finished call to 'Core.Provider.OpenaiApi.OpenAILLM.acompletion_text' after 0.012(s), this was the 1st time calling it.
2025-11-15 13:50:50.648 | WARNING  | tenacity.after:log_it:44 - Finished call to 'Core.Provider.OpenaiApi.OpenAILLM.acompletion_text' after 0.242(s), this was the 2nd time calling it.
2025-11-15 13:50:51.677 | WARNING  | tenacity.after:log_it:44 - Finished call to 'Core.Provider.OpenaiApi.OpenAILLM.acompletion_text' after 1.271(s), this was the 3rd time calling it.
2025-11-15 13:50:55.216 | WARNING  | tenacity.after:log_it:44 - Finished call to 'Core.Provider.OpenaiApi.OpenAILLM.acompletion_text' after 4.809(s), this was the 4th time calling it.
2025-11-15 13:50:58.859 | WARNING  | tenacity.after:log_it:44 - Finished call to 'Core.Provider.OpenaiApi.OpenAILLM.acompletion_text' after 8.453(s), this was the 5th time calling it.
2025-11-15 13:51:09.091 | WARNING  | tenacity.after:log_it:44 - Finished call to 'Core.Provider.OpenaiApi.OpenAILLM.acompletion_text' after 18.685(s), this was the 6th time calling it.
2025-11-15 13:51:09.091 | ERROR    | Core.Common.Utils:log_and_reraise:312 - Retry attempts exhausted. Last exception: Error code: 405 - {'detail': 'Method Not Allowed'}
2025-11-15 13:51:09.091 | WARNING  | Core.Common.Utils:log_and_reraise:313 - 
Recommend going to https://deepwisdom.feishu.cn/wiki/MsGnwQBjiif9c3koSJNcYaoSnu4#part-XdatdVlhEojeAfxaaEZcMV3ZniQ
See FAQ 5.8

2025-11-15 13:51:09.091 | ERROR    | Core.Engine.GraphRAGEngine:process_documents:238 - âŒ Document processing failed: Error code: 405 - {'detail': 'Method Not Allowed'}
2025-11-15 13:51:09.091 | ERROR    | __main__:main:243 - Application execution failed
Traceback (most recent call last):

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/main.py", line 252, in <module>
    asyncio.run(main())
    â”‚       â”‚   â”” <function main at 0x720917c55260>
    â”‚       â”” <function run at 0x720a9b999ee0>
    â”” <module 'asyncio' from '/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/__init__.py'>

  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           â”‚      â”‚   â”” <coroutine object main at 0x720917eafde0>
           â”‚      â”” <function Runner.run at 0x720a9b84d620>
           â”” <asyncio.runners.Runner object at 0x720a4e564d50>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           â”‚    â”‚     â”‚                  â”” <Task pending name='Task-1' coro=<main() running at /data2/chhuangab/projects/GraphRAG-Bench/src/framework/main.py:243> cb=[_...
           â”‚    â”‚     â”” <function BaseEventLoop.run_until_complete at 0x720a9b84b1a0>
           â”‚    â”” <_UnixSelectorEventLoop running=True closed=False debug=False>
           â”” <asyncio.runners.Runner object at 0x720a4e564d50>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/base_events.py", line 641, in run_until_complete
    self.run_forever()
    â”‚    â”” <function BaseEventLoop.run_forever at 0x720a9b84b100>
    â”” <_UnixSelectorEventLoop running=True closed=False debug=False>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/base_events.py", line 608, in run_forever
    self._run_once()
    â”‚    â”” <function BaseEventLoop._run_once at 0x720a9b84cf40>
    â”” <_UnixSelectorEventLoop running=True closed=False debug=False>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/base_events.py", line 1936, in _run_once
    handle._run()
    â”‚      â”” <function Handle._run at 0x720a9b99a980>
    â”” <Handle <TaskStepMethWrapper object at 0x7208e75a7430>()>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
    â”‚    â”‚            â”‚    â”‚           â”‚    â”” <member '_args' of 'Handle' objects>
    â”‚    â”‚            â”‚    â”‚           â”” <Handle <TaskStepMethWrapper object at 0x7208e75a7430>()>
    â”‚    â”‚            â”‚    â”” <member '_callback' of 'Handle' objects>
    â”‚    â”‚            â”” <Handle <TaskStepMethWrapper object at 0x7208e75a7430>()>
    â”‚    â”” <member '_context' of 'Handle' objects>
    â”” <Handle <TaskStepMethWrapper object at 0x7208e75a7430>()>

> File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/main.py", line 223, in main
    await app.process_documents(force_rebuild=args.force_rebuild)
          â”‚   â”‚                               â”‚    â”” False
          â”‚   â”‚                               â”” Namespace(opt='Option/merged_config.yaml', dataset_name='GraphRAG-Bench', method='hippo_rag', force_rebuild=False, max_querie...
          â”‚   â”” <function GraphRAGApplication.process_documents at 0x720917e33920>
          â”” <__main__.GraphRAGApplication object at 0x72092227cd90>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/main.py", line 63, in process_documents
    await self.engine.process_documents(corpus, force_rebuild=force_rebuild)
          â”‚    â”‚      â”‚                 â”‚                     â”” False
          â”‚    â”‚      â”‚                 â”” [{'title': 'What is an algorithm? N/A N/A', 'content': '\n\nIntroduction \n0.1 What is an algorithm? \nAn algorithm is an exp...
          â”‚    â”‚      â”” <function GraphRAGEngine.process_documents at 0x720a41380900>
          â”‚    â”” GraphRAGEngine(config=MergedConfig(extra_fields=None, working_dir='./Data/GraphRAG-Bench', exp_name='default', data_root='./D...
          â”” <__main__.GraphRAGApplication object at 0x72092227cd90>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Engine/GraphRAGEngine.py", line 198, in process_documents
    await self._execute_stage("graph_construction", chunks, force_rebuild)
          â”‚    â”‚                                    â”‚       â”” False
          â”‚    â”‚                                    â”” [TextChunk(tokens=1200, chunk_id='0', content="{'title': 'What is an algorithm? N/A N/A', 'content': '\\n\\nIntroduction \\n0...
          â”‚    â”” <function GraphRAGEngine._execute_stage at 0x720a413809a0>
          â”” GraphRAGEngine(config=MergedConfig(extra_fields=None, working_dir='./Data/GraphRAG-Bench', exp_name='default', data_root='./D...

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Engine/GraphRAGEngine.py", line 246, in _execute_stage
    await stage.execute(*args, **kwargs)
          â”‚     â”‚        â”‚       â”” {}
          â”‚     â”‚        â”” ([TextChunk(tokens=1200, chunk_id='0', content="{'title': 'What is an algorithm? N/A N/A', 'content': '\\n\\nIntroduction \\n...
          â”‚     â”” <function EntityRelationGraphBuilder.execute at 0x7208e71ef4c0>
          â”” <Core.Graph.GraphBuilderFactory.EntityRelationGraphBuilder object at 0x7209159583d0>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Graph/GraphBuilderFactory.py", line 95, in execute
    self.graph = await self._build_graph(chunks)
    â”‚    â”‚             â”‚    â”‚            â”” [TextChunk(tokens=1200, chunk_id='0', content="{'title': 'What is an algorithm? N/A N/A', 'content': '\\n\\nIntroduction \\n0...
    â”‚    â”‚             â”‚    â”” <function EntityRelationGraphBuilder._build_graph at 0x7208e71ef560>
    â”‚    â”‚             â”” <Core.Graph.GraphBuilderFactory.EntityRelationGraphBuilder object at 0x7209159583d0>
    â”‚    â”” None
    â”” <Core.Graph.GraphBuilderFactory.EntityRelationGraphBuilder object at 0x7209159583d0>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Graph/GraphBuilderFactory.py", line 107, in _build_graph
    entities, relationships = await self._extract_entities_relations(chunk)
                                    â”‚    â”‚                           â”” TextChunk(tokens=1200, chunk_id='0', content="{'title': 'What is an algorithm? N/A N/A', 'content': '\\n\\nIntroduction \\n0....
                                    â”‚    â”” <function EntityRelationGraphBuilder._extract_entities_relations at 0x7208e71ef600>
                                    â”” <Core.Graph.GraphBuilderFactory.EntityRelationGraphBuilder object at 0x7209159583d0>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Graph/GraphBuilderFactory.py", line 135, in _extract_entities_relations
    entities = await self._named_entity_recognition(chunk.content)
                     â”‚    â”‚                         â”‚     â”” "{'title': 'What is an algorithm? N/A N/A', 'content': '\\n\\nIntroduction \\n0.1 What is an algorithm? \\nAn algorithm is an...
                     â”‚    â”‚                         â”” TextChunk(tokens=1200, chunk_id='0', content="{'title': 'What is an algorithm? N/A N/A', 'content': '\\n\\nIntroduction \\n0....
                     â”‚    â”” <function EntityRelationGraphBuilder._named_entity_recognition at 0x7208e71ef6a0>
                     â”” <Core.Graph.GraphBuilderFactory.EntityRelationGraphBuilder object at 0x7209159583d0>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Graph/GraphBuilderFactory.py", line 171, in _named_entity_recognition
    response = await self.llm.aask(ner_messages, format="json")
                     â”‚    â”‚   â”‚    â”” 'Your task is to extract named entities from the given paragraph. \nRespond with a JSON list of entities.\n\nPlease reference...
                     â”‚    â”‚   â”” <function BaseLLM.aask at 0x72091593a3e0>
                     â”‚    â”” <Core.Provider.OpenaiApi.OpenAILLM object at 0x720915c64150>
                     â”” <Core.Graph.GraphBuilderFactory.EntityRelationGraphBuilder object at 0x7209159583d0>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Provider/BaseLLM.py", line 146, in aask
    rsp = await self.acompletion_text(message, stream=stream, timeout=self.get_timeout(timeout), max_tokens = max_tokens, format = format)
                â”‚    â”‚                â”‚               â”‚               â”‚    â”‚           â”‚                      â”‚                    â”” 'json'
                â”‚    â”‚                â”‚               â”‚               â”‚    â”‚           â”‚                      â”” None
                â”‚    â”‚                â”‚               â”‚               â”‚    â”‚           â”” 0
                â”‚    â”‚                â”‚               â”‚               â”‚    â”” <function BaseLLM.get_timeout at 0x72091593b100>
                â”‚    â”‚                â”‚               â”‚               â”” <Core.Provider.OpenaiApi.OpenAILLM object at 0x720915c64150>
                â”‚    â”‚                â”‚               â”” False
                â”‚    â”‚                â”” [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Your task is to extract named en...
                â”‚    â”” <function OpenAILLM.acompletion_text at 0x72091593be20>
                â”” <Core.Provider.OpenaiApi.OpenAILLM object at 0x720915c64150>

  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/tenacity/asyncio/__init__.py", line 189, in async_wrapped
    return await copy(fn, *args, **kwargs)
                 â”‚    â”‚    â”‚       â”” {'stream': False, 'timeout': 600, 'max_tokens': None, 'format': 'json'}
                 â”‚    â”‚    â”” (<Core.Provider.OpenaiApi.OpenAILLM object at 0x720915c64150>, [{'role': 'system', 'content': 'You are a helpful assistant.'}...
                 â”‚    â”” <function OpenAILLM.acompletion_text at 0x72091593bba0>
                 â”” <AsyncRetrying object at 0x7208e65074d0 (stop=<tenacity.stop.stop_after_attempt object at 0x720915d49d10>, wait=<tenacity.wai...
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/tenacity/asyncio/__init__.py", line 111, in __call__
    do = await self.iter(retry_state=retry_state)
               â”‚    â”‚                â”” <RetryCallState 125382549331216: attempt #6; slept for 18.64; last result: failed (APIStatusError Error code: 405 - {'detail'...
               â”‚    â”” <function AsyncRetrying.iter at 0x720915d6be20>
               â”” <AsyncRetrying object at 0x7208e65074d0 (stop=<tenacity.stop.stop_after_attempt object at 0x720915d49d10>, wait=<tenacity.wai...
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
                   â”‚      â”” <RetryCallState 125382549331216: attempt #6; slept for 18.64; last result: failed (APIStatusError Error code: 405 - {'detail'...
                   â”” <function wrap_to_async_func.<locals>.inner at 0x7208e6dbb240>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
           â”‚     â”‚       â”” {}
           â”‚     â”” (<RetryCallState 125382549331216: attempt #6; slept for 18.64; last result: failed (APIStatusError Error code: 405 - {'detail...
           â”” <function log_and_reraise at 0x720915bfd3a0>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Common/Utils.py", line 319, in log_and_reraise
    raise retry_state.outcome.exception()
          â”‚           â”‚       â”” <function Future.exception at 0x720a9c000cc0>
          â”‚           â”” <Future at 0x7208e727e4d0 state=finished raised APIStatusError>
          â”” <RetryCallState 125382549331216: attempt #6; slept for 18.64; last result: failed (APIStatusError Error code: 405 - {'detail'...

  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/tenacity/asyncio/__init__.py", line 114, in __call__
    result = await fn(*args, **kwargs)
                   â”‚   â”‚       â”” {'stream': False, 'timeout': 600, 'max_tokens': None, 'format': 'json'}
                   â”‚   â”” (<Core.Provider.OpenaiApi.OpenAILLM object at 0x720915c64150>, [{'role': 'system', 'content': 'You are a helpful assistant.'}...
                   â”” <function OpenAILLM.acompletion_text at 0x72091593bba0>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Provider/OpenaiApi.py", line 157, in acompletion_text
    rsp = await self._achat_completion(messages, timeout=self.get_timeout(timeout), max_tokens = max_tokens)
                â”‚    â”‚                 â”‚                 â”‚    â”‚           â”‚                      â”” None
                â”‚    â”‚                 â”‚                 â”‚    â”‚           â”” 600
                â”‚    â”‚                 â”‚                 â”‚    â”” <function BaseLLM.get_timeout at 0x72091593b100>
                â”‚    â”‚                 â”‚                 â”” <Core.Provider.OpenaiApi.OpenAILLM object at 0x720915c64150>
                â”‚    â”‚                 â”” [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Your task is to extract named en...
                â”‚    â”” <function OpenAILLM._achat_completion at 0x72091593b880>
                â”” <Core.Provider.OpenaiApi.OpenAILLM object at 0x720915c64150>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Provider/OpenaiApi.py", line 138, in _achat_completion
    rsp: ChatCompletion = await self.aclient.chat.completions.create(**kwargs)
                                â”‚    â”‚       â”‚    â”‚           â”‚        â”” {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Your task is to ext...
                                â”‚    â”‚       â”‚    â”‚           â”” <function AsyncCompletions.create at 0x720915ee6200>
                                â”‚    â”‚       â”‚    â”” <openai.resources.chat.completions.completions.AsyncCompletions object at 0x7208e65072d0>
                                â”‚    â”‚       â”” <openai.resources.chat.chat.AsyncChat object at 0x72091597ba10>
                                â”‚    â”” <openai.AsyncOpenAI object at 0x7209159586d0>
                                â”” <Core.Provider.OpenaiApi.OpenAILLM object at 0x720915c64150>

  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2002, in create
    return await self._post(
                 â”‚    â”” <bound method AsyncAPIClient.post of <openai.AsyncOpenAI object at 0x7209159586d0>>
                 â”” <openai.resources.chat.completions.completions.AsyncCompletions object at 0x7208e65072d0>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/openai/_base_client.py", line 1767, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
                 â”‚    â”‚       â”‚        â”‚            â”‚                  â”” openai.AsyncStream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
                 â”‚    â”‚       â”‚        â”‚            â”” False
                 â”‚    â”‚       â”‚        â”” FinalRequestOptions(method='post', url='/chat/completions', params={}, headers=NOT_GIVEN, max_retries=NOT_GIVEN, timeout=600,...
                 â”‚    â”‚       â”” <class 'openai.types.chat.chat_completion.ChatCompletion'>
                 â”‚    â”” <function AsyncAPIClient.request at 0x7209163339c0>
                 â”” <openai.AsyncOpenAI object at 0x7209159586d0>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/openai/_base_client.py", line 1461, in request
    return await self._request(
                 â”‚    â”” <function AsyncAPIClient._request at 0x720916333a60>
                 â”” <openai.AsyncOpenAI object at 0x7209159586d0>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/openai/_base_client.py", line 1562, in _request
    raise self._make_status_error_from_response(err.response) from None
          â”‚    â”” <function BaseClient._make_status_error_from_response at 0x720916330b80>
          â”” <openai.AsyncOpenAI object at 0x7209159586d0>

openai.APIStatusError: Error code: 405 - {'detail': 'Method Not Allowed'}
