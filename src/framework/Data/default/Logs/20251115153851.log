2025-11-15 15:38:59.722 | INFO     | Core.Utils.ComponentRegistry:register_component:273 - âœ… Registered component: graph_builder (general)
2025-11-15 15:38:59.724 | INFO     | Core.Utils.ComponentRegistry:register_component:273 - âœ… Registered component: document_processor (general)
2025-11-15 15:39:04.008 | WARNING  | Core.Indexing.IndexManagerFactory:create_manager:437 - Failed to create embedding model: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 26.62 MiB is free. Process 2258961 has 21.72 GiB memory in use. Including non-PyTorch memory, this process has 1.84 GiB memory in use. Of the allocated memory 1.46 GiB is allocated by PyTorch, and 4.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-11-15 15:39:04.185 | INFO     | Core.Utils.ComponentRegistry:register_component:273 - âœ… Registered component: index_manager (general)
2025-11-15 15:39:04.195 | INFO     | Core.Utils.ComponentRegistry:register_component:273 - âœ… Registered component: query_processor (general)
2025-11-15 15:39:04.196 | INFO     | Core.Utils.ComponentRegistry:register_component:273 - âœ… Registered component: storage_manager (general)
2025-11-15 15:39:04.216 | INFO     | Core.Engine.GraphRAGEngine:process_documents:188 - ğŸš€ Starting document processing workflow
2025-11-15 15:39:04.348 | WARNING  | tenacity.after:log_it:44 - Finished call to 'Core.Provider.OpenaiApi.OpenAILLM.acompletion_text' after 0.034(s), this was the 1st time calling it.
2025-11-15 15:39:04.606 | WARNING  | tenacity.after:log_it:44 - Finished call to 'Core.Provider.OpenaiApi.OpenAILLM.acompletion_text' after 0.292(s), this was the 2nd time calling it.
2025-11-15 15:39:05.708 | WARNING  | tenacity.after:log_it:44 - Finished call to 'Core.Provider.OpenaiApi.OpenAILLM.acompletion_text' after 1.394(s), this was the 3rd time calling it.
2025-11-15 15:39:08.689 | WARNING  | tenacity.after:log_it:44 - Finished call to 'Core.Provider.OpenaiApi.OpenAILLM.acompletion_text' after 4.375(s), this was the 4th time calling it.
2025-11-15 15:39:14.387 | WARNING  | tenacity.after:log_it:44 - Finished call to 'Core.Provider.OpenaiApi.OpenAILLM.acompletion_text' after 10.072(s), this was the 5th time calling it.
2025-11-15 15:39:27.564 | WARNING  | tenacity.after:log_it:44 - Finished call to 'Core.Provider.OpenaiApi.OpenAILLM.acompletion_text' after 23.250(s), this was the 6th time calling it.
2025-11-15 15:39:27.565 | ERROR    | Core.Common.Utils:log_and_reraise:312 - Retry attempts exhausted. Last exception: Error code: 405 - {'detail': 'Method Not Allowed'}
2025-11-15 15:39:27.565 | WARNING  | Core.Common.Utils:log_and_reraise:313 - 
Recommend going to https://deepwisdom.feishu.cn/wiki/MsGnwQBjiif9c3koSJNcYaoSnu4#part-XdatdVlhEojeAfxaaEZcMV3ZniQ
See FAQ 5.8

2025-11-15 15:39:27.565 | ERROR    | Core.Engine.GraphRAGEngine:process_documents:238 - âŒ Document processing failed: Error code: 405 - {'detail': 'Method Not Allowed'}
2025-11-15 15:39:27.565 | ERROR    | __main__:main:243 - Application execution failed
Traceback (most recent call last):

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/main.py", line 252, in <module>
    asyncio.run(main())
    â”‚       â”‚   â”” <function main at 0x7e183cf59260>
    â”‚       â”” <function run at 0x7e19c1145ee0>
    â”” <module 'asyncio' from '/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/__init__.py'>

  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           â”‚      â”‚   â”” <coroutine object main at 0x7e183d1afde0>
           â”‚      â”” <function Runner.run at 0x7e19c0b51620>
           â”” <asyncio.runners.Runner object at 0x7e19c0a3c190>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           â”‚    â”‚     â”‚                  â”” <Task pending name='Task-1' coro=<main() running at /data2/chhuangab/projects/GraphRAG-Bench/src/framework/main.py:243> cb=[_...
           â”‚    â”‚     â”” <function BaseEventLoop.run_until_complete at 0x7e19c0b4f1a0>
           â”‚    â”” <_UnixSelectorEventLoop running=True closed=False debug=False>
           â”” <asyncio.runners.Runner object at 0x7e19c0a3c190>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/base_events.py", line 641, in run_until_complete
    self.run_forever()
    â”‚    â”” <function BaseEventLoop.run_forever at 0x7e19c0b4f100>
    â”” <_UnixSelectorEventLoop running=True closed=False debug=False>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/base_events.py", line 608, in run_forever
    self._run_once()
    â”‚    â”” <function BaseEventLoop._run_once at 0x7e19c0b50f40>
    â”” <_UnixSelectorEventLoop running=True closed=False debug=False>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/base_events.py", line 1936, in _run_once
    handle._run()
    â”‚      â”” <function Handle._run at 0x7e19c1146980>
    â”” <Handle <TaskStepMethWrapper object at 0x7e1822cff3a0>()>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/asyncio/events.py", line 84, in _run
    self._context.run(self._callback, *self._args)
    â”‚    â”‚            â”‚    â”‚           â”‚    â”” <member '_args' of 'Handle' objects>
    â”‚    â”‚            â”‚    â”‚           â”” <Handle <TaskStepMethWrapper object at 0x7e1822cff3a0>()>
    â”‚    â”‚            â”‚    â”” <member '_callback' of 'Handle' objects>
    â”‚    â”‚            â”” <Handle <TaskStepMethWrapper object at 0x7e1822cff3a0>()>
    â”‚    â”” <member '_context' of 'Handle' objects>
    â”” <Handle <TaskStepMethWrapper object at 0x7e1822cff3a0>()>

> File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/main.py", line 223, in main
    await app.process_documents(force_rebuild=args.force_rebuild)
          â”‚   â”‚                               â”‚    â”” False
          â”‚   â”‚                               â”” Namespace(opt='Option/merged_config.yaml', dataset_name='GraphRAG-Bench', method='hippo_rag', force_rebuild=False, max_querie...
          â”‚   â”” <function GraphRAGApplication.process_documents at 0x7e183d137920>
          â”” <__main__.GraphRAGApplication object at 0x7e18476b3450>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/main.py", line 63, in process_documents
    await self.engine.process_documents(corpus, force_rebuild=force_rebuild)
          â”‚    â”‚      â”‚                 â”‚                     â”” False
          â”‚    â”‚      â”‚                 â”” [{'title': 'What is an algorithm? N/A N/A', 'content': '\n\nIntroduction \n0.1 What is an algorithm? \nAn algorithm is an exp...
          â”‚    â”‚      â”” <function GraphRAGEngine.process_documents at 0x7e1966380900>
          â”‚    â”” GraphRAGEngine(config=MergedConfig(extra_fields=None, working_dir='./Data/GraphRAG-Bench', exp_name='default', data_root='./D...
          â”” <__main__.GraphRAGApplication object at 0x7e18476b3450>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Engine/GraphRAGEngine.py", line 198, in process_documents
    await self._execute_stage("graph_construction", chunks, force_rebuild)
          â”‚    â”‚                                    â”‚       â”” False
          â”‚    â”‚                                    â”” [TextChunk(tokens=1200, chunk_id='0', content="{'title': 'What is an algorithm? N/A N/A', 'content': '\\n\\nIntroduction \\n0...
          â”‚    â”” <function GraphRAGEngine._execute_stage at 0x7e19663809a0>
          â”” GraphRAGEngine(config=MergedConfig(extra_fields=None, working_dir='./Data/GraphRAG-Bench', exp_name='default', data_root='./D...

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Engine/GraphRAGEngine.py", line 246, in _execute_stage
    await stage.execute(*args, **kwargs)
          â”‚     â”‚        â”‚       â”” {}
          â”‚     â”‚        â”” ([TextChunk(tokens=1200, chunk_id='0', content="{'title': 'What is an algorithm? N/A N/A', 'content': '\\n\\nIntroduction \\n...
          â”‚     â”” <function EntityRelationGraphBuilder.execute at 0x7e18229474c0>
          â”” <Core.Graph.GraphBuilderFactory.EntityRelationGraphBuilder object at 0x7e1822b9b010>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Graph/GraphBuilderFactory.py", line 95, in execute
    self.graph = await self._build_graph(chunks)
    â”‚    â”‚             â”‚    â”‚            â”” [TextChunk(tokens=1200, chunk_id='0', content="{'title': 'What is an algorithm? N/A N/A', 'content': '\\n\\nIntroduction \\n0...
    â”‚    â”‚             â”‚    â”” <function EntityRelationGraphBuilder._build_graph at 0x7e1822947560>
    â”‚    â”‚             â”” <Core.Graph.GraphBuilderFactory.EntityRelationGraphBuilder object at 0x7e1822b9b010>
    â”‚    â”” None
    â”” <Core.Graph.GraphBuilderFactory.EntityRelationGraphBuilder object at 0x7e1822b9b010>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Graph/GraphBuilderFactory.py", line 107, in _build_graph
    entities, relationships = await self._extract_entities_relations(chunk)
                                    â”‚    â”‚                           â”” TextChunk(tokens=1200, chunk_id='0', content="{'title': 'What is an algorithm? N/A N/A', 'content': '\\n\\nIntroduction \\n0....
                                    â”‚    â”” <function EntityRelationGraphBuilder._extract_entities_relations at 0x7e1822947600>
                                    â”” <Core.Graph.GraphBuilderFactory.EntityRelationGraphBuilder object at 0x7e1822b9b010>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Graph/GraphBuilderFactory.py", line 135, in _extract_entities_relations
    entities = await self._named_entity_recognition(chunk.content)
                     â”‚    â”‚                         â”‚     â”” "{'title': 'What is an algorithm? N/A N/A', 'content': '\\n\\nIntroduction \\n0.1 What is an algorithm? \\nAn algorithm is an...
                     â”‚    â”‚                         â”” TextChunk(tokens=1200, chunk_id='0', content="{'title': 'What is an algorithm? N/A N/A', 'content': '\\n\\nIntroduction \\n0....
                     â”‚    â”” <function EntityRelationGraphBuilder._named_entity_recognition at 0x7e18229476a0>
                     â”” <Core.Graph.GraphBuilderFactory.EntityRelationGraphBuilder object at 0x7e1822b9b010>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Graph/GraphBuilderFactory.py", line 171, in _named_entity_recognition
    response = await self.llm.aask(ner_messages, format="json")
                     â”‚    â”‚   â”‚    â”” 'Your task is to extract named entities from the given paragraph. \nRespond with a JSON list of entities.\n\nPlease reference...
                     â”‚    â”‚   â”” <function BaseLLM.aask at 0x7e183ac3e3e0>
                     â”‚    â”” <Core.Provider.OpenaiApi.OpenAILLM object at 0x7e183b11c210>
                     â”” <Core.Graph.GraphBuilderFactory.EntityRelationGraphBuilder object at 0x7e1822b9b010>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Provider/BaseLLM.py", line 146, in aask
    rsp = await self.acompletion_text(message, stream=stream, timeout=self.get_timeout(timeout), max_tokens = max_tokens, format = format)
                â”‚    â”‚                â”‚               â”‚               â”‚    â”‚           â”‚                      â”‚                    â”” 'json'
                â”‚    â”‚                â”‚               â”‚               â”‚    â”‚           â”‚                      â”” None
                â”‚    â”‚                â”‚               â”‚               â”‚    â”‚           â”” 0
                â”‚    â”‚                â”‚               â”‚               â”‚    â”” <function BaseLLM.get_timeout at 0x7e183ac3f100>
                â”‚    â”‚                â”‚               â”‚               â”” <Core.Provider.OpenaiApi.OpenAILLM object at 0x7e183b11c210>
                â”‚    â”‚                â”‚               â”” False
                â”‚    â”‚                â”” [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Your task is to extract named en...
                â”‚    â”” <function OpenAILLM.acompletion_text at 0x7e183ac3fe20>
                â”” <Core.Provider.OpenaiApi.OpenAILLM object at 0x7e183b11c210>

  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/tenacity/asyncio/__init__.py", line 189, in async_wrapped
    return await copy(fn, *args, **kwargs)
                 â”‚    â”‚    â”‚       â”” {'stream': False, 'timeout': 600, 'max_tokens': None, 'format': 'json'}
                 â”‚    â”‚    â”” (<Core.Provider.OpenaiApi.OpenAILLM object at 0x7e183b11c210>, [{'role': 'system', 'content': 'You are a helpful assistant.'}...
                 â”‚    â”” <function OpenAILLM.acompletion_text at 0x7e183ac3fba0>
                 â”” <AsyncRetrying object at 0x7e18224c0c50 (stop=<tenacity.stop.stop_after_attempt object at 0x7e183ac46950>, wait=<tenacity.wai...
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/tenacity/asyncio/__init__.py", line 111, in __call__
    do = await self.iter(retry_state=retry_state)
               â”‚    â”‚                â”” <RetryCallState 138642110058960: attempt #6; slept for 23.18; last result: failed (APIStatusError Error code: 405 - {'detail'...
               â”‚    â”” <function AsyncRetrying.iter at 0x7e183b06fe20>
               â”” <AsyncRetrying object at 0x7e18224c0c50 (stop=<tenacity.stop.stop_after_attempt object at 0x7e183ac46950>, wait=<tenacity.wai...
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
                   â”‚      â”” <RetryCallState 138642110058960: attempt #6; slept for 23.18; last result: failed (APIStatusError Error code: 405 - {'detail'...
                   â”” <function wrap_to_async_func.<locals>.inner at 0x7e1822bd6ca0>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
           â”‚     â”‚       â”” {}
           â”‚     â”” (<RetryCallState 138642110058960: attempt #6; slept for 23.18; last result: failed (APIStatusError Error code: 405 - {'detail...
           â”” <function log_and_reraise at 0x7e183af013a0>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Common/Utils.py", line 319, in log_and_reraise
    raise retry_state.outcome.exception()
          â”‚           â”‚       â”” <function Future.exception at 0x7e19c1300cc0>
          â”‚           â”” <Future at 0x7e18229e43d0 state=finished raised APIStatusError>
          â”” <RetryCallState 138642110058960: attempt #6; slept for 23.18; last result: failed (APIStatusError Error code: 405 - {'detail'...

  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/tenacity/asyncio/__init__.py", line 114, in __call__
    result = await fn(*args, **kwargs)
                   â”‚   â”‚       â”” {'stream': False, 'timeout': 600, 'max_tokens': None, 'format': 'json'}
                   â”‚   â”” (<Core.Provider.OpenaiApi.OpenAILLM object at 0x7e183b11c210>, [{'role': 'system', 'content': 'You are a helpful assistant.'}...
                   â”” <function OpenAILLM.acompletion_text at 0x7e183ac3fba0>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Provider/OpenaiApi.py", line 157, in acompletion_text
    rsp = await self._achat_completion(messages, timeout=self.get_timeout(timeout), max_tokens = max_tokens)
                â”‚    â”‚                 â”‚                 â”‚    â”‚           â”‚                      â”” None
                â”‚    â”‚                 â”‚                 â”‚    â”‚           â”” 600
                â”‚    â”‚                 â”‚                 â”‚    â”” <function BaseLLM.get_timeout at 0x7e183ac3f100>
                â”‚    â”‚                 â”‚                 â”” <Core.Provider.OpenaiApi.OpenAILLM object at 0x7e183b11c210>
                â”‚    â”‚                 â”” [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Your task is to extract named en...
                â”‚    â”” <function OpenAILLM._achat_completion at 0x7e183ac3f880>
                â”” <Core.Provider.OpenaiApi.OpenAILLM object at 0x7e183b11c210>

  File "/data2/chhuangab/projects/GraphRAG-Bench/src/framework/Core/Provider/OpenaiApi.py", line 138, in _achat_completion
    rsp: ChatCompletion = await self.aclient.chat.completions.create(**kwargs)
                                â”‚    â”‚       â”‚    â”‚           â”‚        â”” {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Your task is to ext...
                                â”‚    â”‚       â”‚    â”‚           â”” <function AsyncCompletions.create at 0x7e183b1ee200>
                                â”‚    â”‚       â”‚    â”” <openai.resources.chat.completions.completions.AsyncCompletions object at 0x7e1821bc0dd0>
                                â”‚    â”‚       â”” <openai.resources.chat.chat.AsyncChat object at 0x7e183adef950>
                                â”‚    â”” <openai.AsyncOpenAI object at 0x7e183adbe4d0>
                                â”” <Core.Provider.OpenaiApi.OpenAILLM object at 0x7e183b11c210>

  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2002, in create
    return await self._post(
                 â”‚    â”” <bound method AsyncAPIClient.post of <openai.AsyncOpenAI object at 0x7e183adbe4d0>>
                 â”” <openai.resources.chat.completions.completions.AsyncCompletions object at 0x7e1821bc0dd0>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/openai/_base_client.py", line 1767, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
                 â”‚    â”‚       â”‚        â”‚            â”‚                  â”” openai.AsyncStream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]
                 â”‚    â”‚       â”‚        â”‚            â”” False
                 â”‚    â”‚       â”‚        â”” FinalRequestOptions(method='post', url='/chat/completions', params={}, headers=NOT_GIVEN, max_retries=NOT_GIVEN, timeout=600,...
                 â”‚    â”‚       â”” <class 'openai.types.chat.chat_completion.ChatCompletion'>
                 â”‚    â”” <function AsyncAPIClient.request at 0x7e183b6379c0>
                 â”” <openai.AsyncOpenAI object at 0x7e183adbe4d0>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/openai/_base_client.py", line 1461, in request
    return await self._request(
                 â”‚    â”” <function AsyncAPIClient._request at 0x7e183b637a60>
                 â”” <openai.AsyncOpenAI object at 0x7e183adbe4d0>
  File "/data2/chhuangab/miniconda3/envs/ragbench__light/lib/python3.11/site-packages/openai/_base_client.py", line 1562, in _request
    raise self._make_status_error_from_response(err.response) from None
          â”‚    â”” <function BaseClient._make_status_error_from_response at 0x7e183b634b80>
          â”” <openai.AsyncOpenAI object at 0x7e183adbe4d0>

openai.APIStatusError: Error code: 405 - {'detail': 'Method Not Allowed'}
